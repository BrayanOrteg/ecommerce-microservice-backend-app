# üìä Observaciones sobre Pruebas de Estr√©s

El reporte generado por Locust se encuentra incluido en la entrega, correspondiente a la simulaci√≥n de carga sobre el sistema desplegado en Azure Kubernetes Service (AKS), con infraestructura aprovisionada mediante Terraform. A continuaci√≥n, se presentan los hallazgos y an√°lisis m√°s relevantes:

Actualizaci√≥n

---

## ‚è±Ô∏è Tiempo de Respuesta

### **Promedio**
Se observaron valores promedio de respuesta en torno a los **279.82 milisegundos (0.28 segundos)**, lo cual sugiere latencias relativamente bajas bajo la carga aplicada. Esto es considerado aceptable para la mayor√≠a de aplicaciones web interactivas.

### **Mediana (P50)**
Se ubic√≥ alrededor de los **17 ms**, indicando que la mayor√≠a de las solicitudes tuvieron respuestas muy r√°pidas.

### **Pico (P95)**
Alcanza hasta **1,900 ms**, lo cual indica que al menos el 5% de las peticiones se tardaron m√°s de 1.9 segundos.

**An√°lisis:** Los tiempos de respuesta muestran una distribuci√≥n variable, con la mayor√≠a de solicitudes siendo muy r√°pidas, pero algunas experimentando latencias m√°s altas, posiblemente debido a consultas m√°s complejas o carga en servicios espec√≠ficos.

---

## üöÄ Throughput (Solicitudes por Segundo)

### **M√°ximo observado**
Aproximadamente **1.9 solicitudes por segundo** en el agregado total.

### **Estabilidad**
Se mantiene entre **1.2 y 1.9 req/s** a lo largo de la prueba, con variaciones seg√∫n la fase de la prueba.

La baja cantidad de solicitudes por segundo se debe a que esta fue una prueba de carga limitada con pocos usuarios concurrentes (m√°ximo 5 usuarios), lo que explica el throughput reducido pero estable del sistema.

---

## ‚úÖ Tasa de Errores

### **Errores reportados**
Se identificaron **20 errores HTTP 500** (Internal Server Error) distribuidos en dos servicios:

- **Favourite-service**: 16 errores en el endpoint `/favourite-service/api/favourites`
- **Shipping-service**: 4 errores en el endpoint `/shipping-service/api/shippings`

Estos errores representan fallas internas del servidor que requieren atenci√≥n inmediata, ya que indican problemas en la l√≥gica de negocio, conexiones a base de datos o configuraci√≥n de los microservicios afectados.

**Tasa de error total**: Aproximadamente **44.4%** (20 errores de 45 solicitudes totales), lo cual es una tasa cr√≠tica que requiere intervenci√≥n urgente.

---

# üìã Conclusiones

- **Problemas cr√≠ticos de estabilidad:** El sistema presenta una tasa de errores del 44.4% (20 errores de 45 solicitudes), indicando fallas significativas en dos microservicios.

- **Servicios afectados:** Los servicios de favoritos y env√≠os muestran errores internos del servidor (HTTP 500) que requieren investigaci√≥n inmediata.

- **Rendimiento mixto:** Aunque los tiempos de respuesta para las solicitudes exitosas son aceptables (279.82 ms promedio), la alta tasa de errores compromete severamente la experiencia del usuario.

- **Impacto en la funcionalidad:** Las fallas en servicios cr√≠ticos como favoritos y env√≠os afectan directamente funcionalidades esenciales del e-commerce.

---

# üõ†Ô∏è Recomendaciones

## ‚ö° Acciones Inmediatas (Cr√≠ticas)

- **Investigar errores HTTP 500**: Revisar logs de los servicios `favourite-service` y `shipping-service` para identificar la causa ra√≠z de las fallas.
- **Verificar conectividad de base de datos**: Confirmar que ambos servicios pueden acceder correctamente a sus respectivas bases de datos.
- **Revisar configuraci√≥n**: Validar variables de entorno, cadenas de conexi√≥n y configuraciones de red.

## üéØ Optimizaci√≥n de Backend

- **Manejo de excepciones**: Implementar un manejo robusto de errores en los microservicios afectados.
- **Logging mejorado**: A√±adir logs detallados para facilitar el debugging de errores internos.
- **Validaci√≥n de datos**: Verificar que los endpoints manejen correctamente las validaciones de entrada.

## üõ°Ô∏è Resiliencia del Sistema

- **Circuit Breaker**: Implementar el patr√≥n Circuit Breaker para prevenir cascadas de fallas.
- **Retry policies**: Configurar pol√≠ticas de reintento para operaciones fallidas.
- **Health checks**: Implementar verificaciones de salud m√°s robustas para detectar problemas tempranamente.

## üñ•Ô∏è Infraestructura y Monitoreo

- **Alertas en tiempo real**: Configurar alertas inmediatas para errores HTTP 500 en Prometheus/Grafana.
- **An√°lisis de recursos**: Verificar que los pods tengan suficientes recursos (CPU/memoria) asignados.
- **Escalamiento**: Asegurar que los servicios puedan escalar bajo carga.

## ‚úÖ Validaci√≥n Post-Fix

- **Re-ejecutar pruebas**: Una vez corregidos los errores, repetir las pruebas de carga para validar las correcciones.
- **Pruebas unitarias**: Implementar tests que cubran los escenarios que causaron los errores HTTP 500.
- **Monitoreo continuo**: Establecer supervisi√≥n permanente de estos servicios cr√≠ticos.

